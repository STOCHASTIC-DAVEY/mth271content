{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Exercise: Word vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following corpus contains statements by two Republican presidents, a quote from the bible, and three quotes from the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {                                                \\\n",
    "'Lincoln1865': \n",
    "'With malice toward none, with charity for all ...'  + \n",
    "'let us strive on to finish the work we are in ... ' + \n",
    "'to do all which may achieve and cherish a just and lasting peace, ' + \n",
    "'among ourselves, and with all nations.',         \n",
    "\n",
    "'TrumpMay26': \n",
    "'There is NO WAY (ZERO!) that Mail-In Ballots ' + \n",
    "'will be anything less than substantially fraudulent.',\n",
    "     \n",
    "'Wikipedia': \n",
    "'In 1998, Oregon became the first state in the US ' + \n",
    "'to conduct all voting exclusively by mail.',\n",
    "\n",
    "'FortuneMay26': \n",
    "'Over the last two decades, about 0.00006% of total ' + \n",
    "'vote-by-mail votes cast were fraudulent.',\n",
    "\n",
    "'TheHillApr07': \n",
    "'Trump voted by mail in the Florida primary.',  \n",
    "\n",
    "'KingJamesBible': \n",
    "'Wherefore laying aside all malice, and all guile, and ' + \n",
    "'hypocrisies, and envies, and all evil speakings',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1:** Use scikit-learn's `CountVectorizer` to make the term-document matrix, particularly noting what the rows and columns correspond to (and compare with  the [LSA lecture](17_LSA.ipynb)).  Display it as a data frame labeled with words and document keys. Does `CountVectorizer` lemmatize the words? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2:** Combine `CountVectorizer` (see its doc string for help) with a tokenizer function you write using spacy's lemmatization (per what you learnt in the [LSA lecture](17_LSA.ipynb)). Remake the term-document matrix. Display your answer. (Your matrix size will depend on whether you used `stop_words='english'` argument of `CountVectorizer`, and may even depend on which version of spacy you are using, since lemmatization has  changed across versions.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3:** Use LSA to compute three dimensional representations of all documents and words using your term-document matrix from Task 2. Print out your vector representation of `vote` (which will obviously depend on the matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4:** Write a function to compute the cosine of the angle between the spans of two word vectors.  Compute the cosine of the angle between `malice` and `vote`.  Compute the cosine of the angle between `mail` and `vote`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5:** In order to moderate the influence of words that appear very frequently, the TF-IDF matrix in often used instead of the term-document matrix.  The term frequency-inverse document frequency (TFâ€“IDF) matrix weights the word counts by a measure of how often they appear in the documents according to a formula found in [scikit-learn user guide](https://scikit-learn.org/stable/modules/feature_extraction.html?highlight=term%20frequency). Compute the TF-IDF matrix for the above corpus using `TfidfVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6:**  Recompute the two cosines of Task 4, now using the TF-IDF matrix of Task 5 and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
